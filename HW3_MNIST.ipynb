{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_iYcla4kCX67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "JodgHy9nCX68",
        "outputId": "b3240527-44df-4349-f691-c419c1321c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # Load MNIST or FMNIST\n",
        "assert X_train.shape == (60000, 28, 28)\n",
        "assert X_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "\n",
        "\n",
        "# Display randomly selected data\n",
        "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIRI-uLoCX69",
        "outputId": "55298cd2-d328-4edd-e664-3fda785da79c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of training set is 50000 samples\n",
            "every train example is 28 by 28\n",
            "size of validation set is 10000 samples\n",
            "every validation example is 28 by 28\n",
            "size of training set is 50000 samples\n",
            "every train example has 784 features\n",
            "size of validation set is 10000 samples\n",
            "every validation example has 784 features\n"
          ]
        }
      ],
      "source": [
        "# Split train dataset into train and validation\n",
        "X_val = X_train[50000:60000]\n",
        "X_train = X_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
        "\n",
        "X_train = X_train.reshape(50000, 28*28)\n",
        "X_val = X_val.reshape(10000, 28*28)\n",
        "X_test = X_test.reshape(10000, 28*28)\n",
        "\n",
        "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
        "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
        "\n",
        "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
        "print(\"every validation example has\", str(X_val.shape[1]), \"features\")\n",
        "\n",
        "# Split dataset into batches\n",
        "#train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
        "#test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDyZ8bZjCX69",
        "outputId": "0679ec98-0e7d-4cc5-e134-0731edf1cdf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#Normalize Data\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "X_test = X_test/255\n",
        "# X_train[0]\n",
        "np.max(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIIy313CX69",
        "outputId": "7b03b161-b740-45be-8bb6-5112eb2471e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10000    10], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "size_input = X_train.shape[1]\n",
        "size_hidden1 = 128\n",
        "size_hidden2 = 128\n",
        "size_hidden3 = 128\n",
        "size_output = 10\n",
        "\n",
        "number_of_train_examples = X_train.shape[0]\n",
        "number_of_test_examples = X_test.shape[0]\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "print(tf.shape(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "dGVAl4vZCOKl"
      },
      "outputs": [],
      "source": [
        "L2 = True\n",
        "dropout = False\n",
        "regularizer_rate = 0.01\n",
        "drop_percent = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "obN7WPLpCX69"
      },
      "outputs": [],
      "source": [
        "# Define class to build mlp model\n",
        "class MLP(object):\n",
        " def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
        "    \"\"\"\n",
        "    size_input: int, size of input layer\n",
        "    size_hidden1: int, size of the 1st hidden layer\n",
        "    size_hidden2: int, size of the 2nd hidden layer\n",
        "    size_output: int, size of output layer\n",
        "    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
        "    \"\"\"\n",
        "    self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
        "    size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
        "    \n",
        "    self.tstep = 0\n",
        "\n",
        "    # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1],stddev=0.1)) # Xavier(Fan-in fan-out) and Orthogonal\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
        "    \n",
        "    # Initialize weights between input layer and 1st hidden layer\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
        "    \n",
        "    # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
        "    self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3],stddev=0.1))\n",
        "    # Initialize biases for hidden layer\n",
        "    self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
        "    \n",
        "     # Initialize weights between 2nd hidden layer and output layer\n",
        "    self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output],stddev=0.1))\n",
        "    # Initialize biases for output layer\n",
        "    self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
        "    \n",
        "    # Define variables to be updated during backpropagation\n",
        "    self.variables = [self.W1, self.W2, self.W3, self.W4, self.b1, self.b2, self.b3, self.b4]\n",
        "    self.m0 = tf.zeros([len(self.variables)], tf.float32)\n",
        "    self.v0 = tf.zeros([len(self.variables)], tf.float32)\n",
        "    self.u0 = tf.zeros([len(self.variables)], tf.float32)\n",
        "   \n",
        "  \n",
        " def forward(self, X):\n",
        "    \"\"\"\n",
        "    forward pass\n",
        "    X: Tensor, inputs\n",
        "    \"\"\"\n",
        "    if self.device is not None:\n",
        "      with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
        "        self.y = self.compute_output(X)\n",
        "    else:\n",
        "      self.y = self.compute_output(X)\n",
        "      \n",
        "    return self.y\n",
        "\n",
        " def loss(self, y_pred, y_true):\n",
        "    '''\n",
        "    y_pred - Tensor of shape (batch_size, size_output)\n",
        "    y_true - Tensor of shape (batch_size, size_output)\n",
        "    '''\n",
        "    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
        "    y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
        "    y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    loss_x = cce(y_true_tf, y_pred_tf)\n",
        "    # Use keras or tf_softmax, both should work for any given model\n",
        "    #loss_x = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf))\n",
        "    if L2:\n",
        "      regularizers = tf.nn.l2_loss(self.W1) + tf.nn.l2_loss(self.W2)\n",
        "      loss_x = tf.reduce_mean(loss_x + regularizer_rate * regularizers)\n",
        "    return loss_x\n",
        "\n",
        " def customOptimizer(self, grads):\n",
        "    alpha = 1e-3\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    beta3 = 0.999987\n",
        "    epsilon = 1e-8\n",
        "   \n",
        "    self.m0 = [beta1*ai+ bi*(1.0-beta1) for ai,bi in zip(self.m0,grads)]\n",
        "    self.v0 = [beta2*ai + (1.0-beta2)*bi**2 for ai,bi in zip(self.v0,grads)]\n",
        "    self.u0 = [beta3*ai + (1.0-beta3)*bi**3 for ai,bi in zip(self.u0,grads)]\n",
        "   \n",
        "    m0_bias = [i/(1.0-beta1**self.tstep) for i in self.m0] \n",
        "    v0_bias = [abs(i/(1.0-beta2**self.tstep)) for i in self.v0]\n",
        "    u0_bias = [abs(i/(1.0-beta3**self.tstep)) for i in self.u0]\n",
        "    v0_bias = [i**0.5 for i in v0_bias]\n",
        "    u0_bias = [epsilon*(i**(1.0/3.0)) for i in u0_bias]\n",
        "    for i in range(len(self.variables)):\n",
        "      self.variables[i].assign(self.variables[i]- alpha*m0_bias[i]/(u0_bias[i]+v0_bias[i] + 1e-6)) \n",
        "\n",
        " def backward(self, X_train, y_train, optimizer_type):\n",
        "    \"\"\"\n",
        "    backward pass\n",
        "    \"\"\"\n",
        "    if optimizer_type == 1:\n",
        "      optimizer = tf.keras.optimizers.SGD(learning_rate = 0.05)\n",
        "    elif optimizer_type == 2:\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
        "    elif optimizer_type == 3:\n",
        "      optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.01)\n",
        "      \n",
        "    with tf.GradientTape() as tape:\n",
        "        \n",
        "      predicted = self.forward(X_train)\n",
        "      current_loss = self.loss(predicted, y_train)\n",
        "        \n",
        "    grads = tape.gradient(current_loss, self.variables)\n",
        "    if optimizer_type == 4:\n",
        "      self.customOptimizer(grads)\n",
        "    else:\n",
        "      optimizer.apply_gradients(zip(grads, self.variables))\n",
        "\n",
        "           \n",
        " def compute_output(self, X):\n",
        "    \"\"\"\n",
        "    Custom method to obtain output tensor during forward pass\n",
        "    \"\"\"\n",
        "    # Cast X to float32\n",
        "    X_tf = tf.cast(X, dtype=tf.float32)\n",
        "    #X_tf = X\n",
        "    \n",
        "    # Compute values in hidden layers\n",
        "    z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
        "    h1 = tf.nn.relu(z1)\n",
        "    if dropout:\n",
        "      h1 = tf.nn.dropout(h1,drop_percent)\n",
        "    z2 = tf.matmul(h1, self.W2) + self.b2\n",
        "    h2 = tf.nn.relu(z2)\n",
        "    if dropout:\n",
        "      h2 = tf.nn.dropout(h2,drop_percent)\n",
        "    z3 = tf.matmul(h2, self.W3) + self.b3\n",
        "    h3 = tf.nn.relu(z3)\n",
        "\n",
        "    # Compute output\n",
        "    output = tf.matmul(h3, self.W4) + self.b4\n",
        "    \n",
        "    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
        "    # Second add tf.Softmax(output) and then return this variable\n",
        "    return (output)\n",
        "\n",
        "#  def stderr(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate standard error\n",
        "#      \"\"\"\n",
        "#     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "#     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "#     std_err = std_dev/sqrt(len(y_pred_tf))\n",
        "#     return std_err \n",
        "\n",
        "\n",
        " def var(self,y_pred):\n",
        "#     \"\"\"\n",
        "#      Calculate variance \n",
        "#      \"\"\"\n",
        "     y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
        "     std_dev = np.std(y_pred_tf) #Calculates standard deviation\n",
        "     variance = (std_dev**2) # calculate variance\n",
        "     return variance \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pOnhvVlUCX6-",
        "outputId": "79c4b0e1-020d-4102-a85a-5fe0527826a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Accuracy: 0.8300\n",
            "Number of Epoch = 1 - Average Cross Entropy:= 0.0192849560546875 \n",
            "\n",
            "Validation Accuracy: 0.8210\n",
            "\n",
            "Train Accuracy: 0.8487\n",
            "Number of Epoch = 2 - Average Cross Entropy:= 0.006950887451171875 \n",
            "\n",
            "Validation Accuracy: 0.8404\n",
            "\n",
            "Train Accuracy: 0.8584\n",
            "Number of Epoch = 3 - Average Cross Entropy:= 0.005364984130859375 \n",
            "\n",
            "Validation Accuracy: 0.8457\n",
            "\n",
            "Train Accuracy: 0.8622\n",
            "Number of Epoch = 4 - Average Cross Entropy:= 0.004672795715332031 \n",
            "\n",
            "Validation Accuracy: 0.8516\n",
            "\n",
            "Train Accuracy: 0.8650\n",
            "Number of Epoch = 5 - Average Cross Entropy:= 0.004278532104492187 \n",
            "\n",
            "Validation Accuracy: 0.8540\n",
            "\n",
            "Train Accuracy: 0.8664\n",
            "Number of Epoch = 6 - Average Cross Entropy:= 0.004018226318359375 \n",
            "\n",
            "Validation Accuracy: 0.8546\n",
            "\n",
            "Train Accuracy: 0.8676\n",
            "Number of Epoch = 7 - Average Cross Entropy:= 0.003832528991699219 \n",
            "\n",
            "Validation Accuracy: 0.8540\n",
            "\n",
            "Train Accuracy: 0.8692\n",
            "Number of Epoch = 8 - Average Cross Entropy:= 0.003689427795410156 \n",
            "\n",
            "Validation Accuracy: 0.8555\n",
            "\n",
            "Train Accuracy: 0.8721\n",
            "Number of Epoch = 9 - Average Cross Entropy:= 0.0035680352783203123 \n",
            "\n",
            "Validation Accuracy: 0.8584\n",
            "\n",
            "Train Accuracy: 0.8745\n",
            "Number of Epoch = 10 - Average Cross Entropy:= 0.0034767156982421876 \n",
            "\n",
            "Validation Accuracy: 0.8612\n",
            "\n",
            "Total time taken (in seconds): 206.43\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Initialize model using CPU\n",
        "mlp_on_cpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
        "randseed = 11\n",
        "time_start = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    \n",
        "  loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
        "  lt = 0\n",
        "    \n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(randseed)).batch(128)\n",
        "  kz = 0\n",
        "  accuracy_z = 0.0\n",
        "  cur_train_acc = 0.0\n",
        "  mlp_on_cpu.tstep = 0\n",
        "  for inputs, outputs in train_ds:\n",
        "    mlp_on_cpu.tstep += 1\n",
        "    qw, tr = tf.shape(inputs)\n",
        "    kz = kz + 1\n",
        "    preds = mlp_on_cpu.forward(inputs) \n",
        "    loss_total = loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "    lt = lt + mlp_on_cpu.loss(preds, outputs)\n",
        "    mlp_on_cpu.backward(inputs, outputs,4)\n",
        "    #mlp_on_cpu.customBackward(inputs,outputs)\n",
        "\n",
        "  preds = mlp_on_cpu.forward(X_train)\n",
        "  # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
        "  preds = tf.nn.softmax(preds)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
        "  accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_train_acc += accuracy_z.numpy()\n",
        "  ds = cur_train_acc\n",
        "  print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
        "  print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
        "  preds_val = mlp_on_cpu.forward(X_val)\n",
        "  preds_val = tf.nn.softmax(preds_val)\n",
        "  correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "  cur_val_acc = accuracy.numpy()\n",
        "\n",
        "  print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
        "  \n",
        "  plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
        "\n",
        "        \n",
        "time_taken = time.time() - time_start\n",
        "    \n",
        "# Validate model\n",
        "    \n",
        "\n",
        "\n",
        "print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
        "#For per epoch_time = Total_Time / Number_of_epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eNKeELWCX6_",
        "outputId": "0b9692b3-2c29-4a7c-a61e-5a7e8b9a4918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.1251\n",
            "\n",
            "Test Accuracy: 0.8551\n"
          ]
        }
      ],
      "source": [
        "# Initialize\n",
        "test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
        "correct_prediction = tf.Variable(0, dtype=tf.float32)\n",
        "\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
        "\n",
        "\n",
        "#test_loss_total = 0.0\n",
        "for inputs, outputs in test_ds:\n",
        "  preds = mlp_on_cpu.forward(inputs)\n",
        "  test_loss_total = test_loss_total + mlp_on_cpu.loss(preds, outputs)\n",
        "print('Test loss: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))\n",
        "\n",
        "# Test model\n",
        "preds_test = mlp_on_cpu.forward(X_test)\n",
        "preds_test = tf.nn.softmax(preds_test)\n",
        "correct_prediction = tf.equal(tf.argmax(preds_test, 1), tf.argmax(y_test, 1))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "cur_test_acc = accuracy.numpy()\n",
        "print('\\nTest Accuracy: {:.4f}'.format(cur_test_acc))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "5DRomYsUCX6_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYsXWqI_CX6_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW3_MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}